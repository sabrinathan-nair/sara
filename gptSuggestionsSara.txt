# Phase 1: Foundational & Low Hanging Fruit (Weeks 1-3)

## Core Ergonomics & API Usability
- [ ] Enable `OverloadedLabels` for cleaner column references (e.g., `#Salary`)
- [ ] Define `IsLabel` instances for `col`, `mutate`, `filterByBoolColumn`
- [ ] Add chaining operators: (`|>`, `&`, `then`, etc.) for readable pipelines
- [ ] Create user-friendly aliases: `selectCol`, `dropCol`, `renameCol`
- [ ] Support column access via lens-like syntax: `row ^. #Age`

## Data Exploration Utilities
- [ ] `head`, `tail`, `sample`: preview first/last/random rows
- [ ] `numRows`, `numCols`: DataFrame dimensions
- [ ] `schemaOf`: pretty print current schema

## DataFrame Manipulation Basics
- [ ] Add `select` for column subsetting: `select @["Age", "Name"] df`
- [ ] Add `drop` to remove columns: `drop @"ID" df`
- [ ] Add `rename @"Old" @"New"` for renaming columns

## Testing + Debugging (Basic)
- [ ] Extend QuickCheck properties for transformations
- [ ] Add law-based tests for `filter`, `mutate`, etc.

---

# Phase 2: Intermediate Features & Ecosystem (Weeks 4-7)

## Data Exploration Utilities (continued)
- [ ] `describe`: compute count, mean, std, min, max per numeric column
- [ ] `summary`: R-style summary for each column (min, max, unique, etc.)

## File I/O + Interop
- [ ] Add JSONL (newline-delimited JSON) streaming reader
- [ ] Add support for compressed file formats (`.gz`, `.bz2`)
- [ ] Add CLI interface (`sara-cli`) for terminal use

## Joins and Relational Features
- [ ] Support `leftJoin`, `innerJoin`, `outerJoin` with schema merging
- [ ] Auto-infer join keys from schema or via DSL: `on @["ID"]`
- [ ] Column disambiguation logic for joining overlapping column names
- [ ] Add `concatRows`, `concatCols` for union/merge

## DataFrame Manipulation Advanced
- [ ] Allow safe schema projections from wide to narrow types

## Performance + Streaming (Initial)
- [ ] Chunk size configuration for streaming reads
- [ ] Add lazy reading from huge CSVs with skip header logic

## Testing + Debugging (Advanced)
- [ ] Add `explain` to show transformation chain
- [ ] Add snapshot test support for intermediate DataFrames

---

# Phase 3: Grouping, Aggregation & Performance (Weeks 8-12)

## Grouping + Aggregation
- [ ] Introduce `groupBy @["Col1", "Col2"]` returning GroupedDataFrame
- [ ] Add `summarise @["Col"] mean` / `agg` syntax with DSL
- [ ] Allow multiple aggregations: `agg [("Age", mean), ("Salary", max)]`
- [ ] `count`, `mean`, `sum`, `median`, `stdDev`, `min`, `max`

## Performance + Streaming (Advanced)
- [ ] Stream fusion: auto-collapse chained maps/filters
- [ ] Memory benchmarking: compare static vs streaming
- [ ] Parallel streaming via `async`, `foldl`, `streaming-with`

## File I/O + Interop (Advanced)
- [ ] Add Parquet reader/writer using `parquet` or `arrow`
- [ ] Add Excel `.xlsx` reader (via `spreadsheet` or `libxlsxwriter`)
- [ ] Add SQLite read/write functions (`sqlite-simple`)

---

# Phase 4: Advanced Schema System & Ecosystem Integration (Weeks 13-18)

## Advanced Schema System
- [ ] Partial schema inference with optional columns
- [ ] Support for nullable / optional columns
- [ ] Schema diffs: compare two schemas and generate migration suggestions
- [ ] Row-level schema refinement (dynamic rows with safe partials)
- [ ] Column metadata: units, descriptions, constraints

## Ecosystem Integration
- [ ] `Export to Python` via Arrow IPC / HDF5
- [ ] WebAssembly backend: make Sara run in browser (via `ghc-wasm-meta`)
- [ ] Integration with `shelly` or `shake` for data workflows
- [ ] `sara-widgets` library for interactive dashboards (later)
- [ ] Notebook-style REPL experience (`ihaskell`, `hvega`, `diagrams`)

---

# Phase 5: Visualization, ML & Documentation (Weeks 19+)

## Plotting DSL
- [ ] Add plotting DSL: `plot df [geom Point [x #Age, y #Salary]]`
- [ ] Backends: SVG, Cairo, VegaLite (`hvega`)
- [ ] Built-in charts: line, bar, scatter, histogram, boxplot
- [ ] Support for themes, labels, legends, scales
- [ ] Interactive plotting hooks (if frontend is added)

## Machine Learning + Stats Extensions
- [ ] `standardize`, `normalize`, `oneHotEncode` columns
- [ ] Encode categorical variables with auto-detection
- [ ] Add `Sara.Stats`: mean, variance, covariance matrix, correlation
- [ ] Model-friendly split: `trainTestSplit`, `kFold`
- [ ] Interop with Hasktorch or export to scikit-learn compatible CSV

## Documentation & Community
- [ ] Auto-generate Haddock with code examples
- [ ] Create `Sara.Tutorial` and `Sara.Cookbook` modules
- [ ] Add README usage examples and schema explanation
- [ ] Add badges for build, coverage, haddocks
- [ ] Publish to Hackage and Stackage

